{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f93f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.backend.image import load_image, show_image\n",
    "from paz.applications import HaarCascadeFrontalFace, MiniXceptionFER\n",
    "import paz.processors as pr\n",
    "from paz.backend.image.image import crop_image\n",
    "from paz.processors.detection import CropBoxes2D\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from paz.abstract import SequentialProcessor\n",
    "from retinaface import RetinaFace\n",
    "from paz.abstract.messages import Box2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00102b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Frame 1------\n",
      "Boxes:  [Box2D(495, 302, 708, 553, 0, None)] <class 'list'>\n",
      "[1, 'sad']\n",
      "--------Frame 2------\n",
      "Boxes:  [Box2D(494, 303, 708, 554, 0, None)] <class 'list'>\n",
      "[2, 'sad']\n",
      "--------Frame 3------\n",
      "Boxes:  [Box2D(494, 304, 707, 557, 0, None)] <class 'list'>\n",
      "[3, 'sad']\n",
      "--------Frame 4------\n",
      "Boxes:  [Box2D(497, 302, 715, 566, 0, None)] <class 'list'>\n",
      "[4, 'sad']\n",
      "----------------Done getting emotion------------------\n",
      "Front face emotion labeling:  ['1' 'sad' '2' 'sad' '3' 'sad' '4' 'sad']\n"
     ]
    }
   ],
   "source": [
    "class process_front_images():\n",
    "    def __init__(self):\n",
    "        self.folder_path = Path('EECE571L\\Driver_emotion_detection\\DMD\\s3_rgb_face').__str__()\n",
    "        self.result = np.array([]) # 2D array with element [frame_number, emotion]\n",
    "        \n",
    "    def get_emotion(self):\n",
    "        for frame_number in range(1, 5):\n",
    "            path = self.folder_path + '\\%(number)06d.png' % {\"number\": frame_number}\n",
    "            image = load_image(path)\n",
    "    \n",
    "            print('--------Frame {fnumber}------'.format(fnumber = frame_number))\n",
    "            crop = CropBoxes2D()\n",
    "            face = RetinaFace.detect_faces(path)\n",
    "            coordinates = face['face_1']['facial_area']\n",
    "            boxes2D = [Box2D(coordinates, score=0)]\n",
    "            print('Boxes: ', boxes2D, type(boxes2D))\n",
    "            if (len(boxes2D) == 0):\n",
    "                continue\n",
    "                \n",
    "            elif (len(boxes2D) >= 2):\n",
    "                areas = np.array([])\n",
    "                for box in boxes2D:\n",
    "                    area = (box.coordinates[2]-box.coordinates[0]) * (box.coordinates[3]-box.coordinates[1])\n",
    "                    areas = np.append(areas, area)\n",
    "                indices_excluding_max = np.where(areas != np.amax(areas))[0]\n",
    "                print('Indices to remove', indices_excluding_max)\n",
    "                for i in indices_excluding_max:\n",
    "                    boxes2D = np.delete(boxes2D, i)\n",
    "                print('After removing smaller boxes: ', boxes2D)            \n",
    "            \n",
    "            cropped_images = crop(image, boxes2D)\n",
    "            show_image(cropped_images[0])\n",
    "            classify = MiniXceptionFER()\n",
    "            emotion = classify(cropped_images[0])['class_name']\n",
    "            print([frame_number, emotion])\n",
    "            self.result = np.append(self.result, [frame_number, emotion])\n",
    "        print('----------------Done getting emotion------------------')\n",
    "        return self.result\n",
    "    \n",
    "front_image_processor = process_front_images()\n",
    "emotion_result = front_image_processor.get_emotion()\n",
    "print('Front face emotion labeling: ', emotion_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc44b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Frame 1------\n",
      "Boxes:  [Box2D(393, 25, 541, 238, 0, None)] <class 'list'>\n",
      "--------Frame 2------\n",
      "Boxes:  [Box2D(395, 28, 543, 238, 0, None)] <class 'list'>\n",
      "--------Frame 3------\n",
      "Boxes:  [Box2D(397, 28, 543, 239, 0, None)] <class 'list'>\n",
      "--------Frame 4------\n",
      "Boxes:  [Box2D(398, 30, 543, 240, 0, None)] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "class process_side_images():\n",
    "    def __init__(self):\n",
    "        self.folder_path = Path('EECE571L\\Driver_emotion_detection\\DMD\\s3_rgb_body').__str__()\n",
    "        self.result = np.array([0, 0]) # path format?\n",
    "    def get_face_image(self):\n",
    "        for frame_number in range(1, 5):\n",
    "            path = self.folder_path + '\\%(number)06d.png' % {\"number\": frame_number}\n",
    "            image = load_image(path)\n",
    "    \n",
    "            print('--------Frame {fnumber}------'.format(fnumber = frame_number))\n",
    "            crop = CropBoxes2D()\n",
    "            face = RetinaFace.detect_faces(path)\n",
    "            coordinates = face['face_1']['facial_area']\n",
    "            boxes2D = [Box2D(coordinates, score=0)]\n",
    "            print('Boxes: ', boxes2D, type(boxes2D))\n",
    "            if (len(boxes2D) == 0):\n",
    "                continue\n",
    "                \n",
    "            elif (len(boxes2D) >= 2):\n",
    "                areas = np.array([])\n",
    "                for box in boxes2D:\n",
    "                    area = (box.coordinates[2]-box.coordinates[0]) * (box.coordinates[3]-box.coordinates[1])\n",
    "                    areas = np.append(areas, area)\n",
    "                indices_excluding_max = np.where(areas != np.amax(areas))[0]\n",
    "                print('Indices to remove', indices_excluding_max)\n",
    "                for i in indices_excluding_max:\n",
    "                    boxes2D = np.delete(boxe\n",
    "                                        s2D, i)\n",
    "                print('After removing smaller boxes: ', boxes2D)            \n",
    "            \n",
    "            cropped_images = crop(image, boxes2D)\n",
    "            show_image(cropped_images[0])\n",
    "\n",
    "side_processor = process_side_images()\n",
    "side_processor.get_face_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4ab2e",
   "metadata": {},
   "source": [
    "### Code for detecting faces using PAZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0a33b",
   "metadata": {},
   "source": [
    "Poor detection performance\n",
    "    4 out of 5 images were detected wrongly - boxes not appears around the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22eb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = self.folder_path + '\\%(number)06d.png' % {\"number\": frame_number}\n",
    "            image = load_image(path)\n",
    "    \n",
    "            print('--------Frame {fnumber}------'.format(fnumber = frame_number))\n",
    "            detect = HaarCascadeFrontalFace(draw=False)\n",
    "            crop = CropBoxes2D()\n",
    "            inference = detect(image)\n",
    "            boxes2D = inference['boxes2D']\n",
    "            print('Boxes: ', boxes2D, type(boxes2D))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
